{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35911d5",
   "metadata": {},
   "source": [
    "# CHFS IOR Result Visualizer\n",
    "\n",
    "`results/chfs/*/ior_results/ior_result_*.json` から IOR のサマリ JSON を読み込み、操作別の帯域やレイテンシを可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b56b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from IPython.display import display\n",
    "\n",
    "# 手動で実験を指定する場合はここを編集\n",
    "SELECTED_EXPERIMENTS: list[str] | None = None  # 最新の実験を自動選択\n",
    "\n",
    "# Plot style configuration\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 12,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"figure.facecolor\": \"white\",\n",
    "    \"axes.facecolor\": \"white\",\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.3,\n",
    "})\n",
    "pl.Config.set_tbl_rows(100)\n",
    "\n",
    "DATA_DIR = (Path.cwd() / \"processed\" / \"chfs\").resolve()\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR = (Path.cwd() / \"fig\" / \"chfs\").resolve()\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save(fig, name: str) -> None:\n",
    "    for ext in (\"png\", \"pdf\"):\n",
    "        fig.savefig(FIG_DIR / f\"{name}.{ext}\", bbox_inches=\"tight\", dpi=150)\n",
    "\n",
    "def comma_formatter(value, _):\n",
    "    return f\"{value:,.0f}\"\n",
    "\n",
    "def slugify(value: str) -> str:\n",
    "    cleaned = re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", value)\n",
    "    return cleaned.strip(\"_\") or \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb50f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_results_root() -> Path:\n",
    "    candidates = [\n",
    "        Path(\"results\"),\n",
    "        Path(\"..\") / \"results\",\n",
    "        Path(\"../..\") / \"results\",\n",
    "    ]\n",
    "    for candidate in candidates:\n",
    "        if candidate.exists():\n",
    "            return candidate.resolve()\n",
    "    raise FileNotFoundError(\"results ディレクトリが見つかりません。ノートブックの位置を確認してください。\")\n",
    "\n",
    "results_root = resolve_results_root()\n",
    "print(f\"Using results directory: {results_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "json-fix",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ior_json(content: str) -> str:\n",
    "    \"\"\"Fix common IOR JSON output format bugs.\n",
    "    \n",
    "    IOR 4.0.0 has several JSON formatting issues:\n",
    "    1. Double closing brackets after Results array: ]] -> ]\n",
    "    2. Extra closing bracket at the end of tests array\n",
    "    3. Trailing commas before closing braces/brackets\n",
    "    \"\"\"\n",
    "    content = re.sub(r'\\]\\s*\\]\\s*,\\s*\"max\":', r'], \"max\":', content)\n",
    "    content = re.sub(r'\\}\\s*\\]\\s*\\]\\s*,\\s*\"summary\":', r'}], \"summary\":', content)\n",
    "    content = re.sub(r',\\s*\\}', '}', content)\n",
    "    content = re.sub(r',\\s*\\]', ']', content)\n",
    "    return content\n",
    "\n",
    "def safe_load_json(path: Path) -> dict | None:\n",
    "    \"\"\"Load JSON file with automatic fix for IOR format issues.\"\"\"\n",
    "    try:\n",
    "        content = path.read_text()\n",
    "        try:\n",
    "            return json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "        fixed_content = fix_ior_json(content)\n",
    "        return json.loads(fixed_content)\n",
    "    except (OSError, json.JSONDecodeError) as exc:\n",
    "        print(f\"Warning: Failed to parse {path}: {exc}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d77ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "IOR_JSON_PATTERN = re.compile(r\"ior_result_(\\d+)\\.json$\")\n",
    "\n",
    "def parse_number(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, (int, float)):\n",
    "        return float(value)\n",
    "    if isinstance(value, str):\n",
    "        cleaned = value.replace(\",\", \"\").strip()\n",
    "        if cleaned == \"\":\n",
    "            return None\n",
    "        try:\n",
    "            return float(cleaned)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def extract_params_from_command(command: str) -> dict:\n",
    "    \"\"\"Extract IOR parameters from command line string.\"\"\"\n",
    "    params = {}\n",
    "    # Transfer size: -t 4m\n",
    "    match = re.search(r'-t\\s+(\\S+)', command)\n",
    "    if match:\n",
    "        params['transfer_size_str'] = match.group(1)\n",
    "    # Block size: -b 512m\n",
    "    match = re.search(r'-b\\s+(\\S+)', command)\n",
    "    if match:\n",
    "        params['block_size_str'] = match.group(1)\n",
    "    # File per proc: -F flag\n",
    "    params['file_per_proc'] = 1 if ' -F' in command or command.endswith('-F') else 0\n",
    "    # CHFS chunk size\n",
    "    match = re.search(r'--chfs\\.chunk_size=(\\d+)', command)\n",
    "    if match:\n",
    "        params['chfs_chunk_size'] = int(match.group(1))\n",
    "    return params\n",
    "\n",
    "def extract_nodes_from_run(run_name: str) -> int | None:\n",
    "    \"\"\"Extract node count from run directory name like '2025.12.04-01.19.22-409253.nqsv-16'.\"\"\"\n",
    "    match = re.search(r'-(\\d+)$', run_name)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def load_ior_json(root: Path) -> tuple[pl.DataFrame, pl.DataFrame]:\n",
    "    summary_records = []\n",
    "    detail_records = []\n",
    "    \n",
    "    # Look for CHFS results\n",
    "    for path in sorted(root.glob(\"chfs/**/ior_results/ior_result_*.json\")):\n",
    "        data = safe_load_json(path)\n",
    "        if data is None:\n",
    "            continue\n",
    "            \n",
    "        rel_parts = path.relative_to(root).parts\n",
    "        match = IOR_JSON_PATTERN.search(path.name)\n",
    "        run_index = int(match.group(1)) if match else None\n",
    "        \n",
    "        command = data.get(\"Command line\", \"\")\n",
    "        cmd_params = extract_params_from_command(command)\n",
    "        \n",
    "        # Extract node count from run directory name\n",
    "        run_name = rel_parts[2] if len(rel_parts) > 2 else \"\"\n",
    "        nnodes = extract_nodes_from_run(run_name)\n",
    "        \n",
    "        base = {\n",
    "            \"ior_file\": str(path.relative_to(root)),\n",
    "            \"collection\": \"/\".join(rel_parts[:-1]),\n",
    "            \"backend\": rel_parts[0] if len(rel_parts) > 0 else \"\",\n",
    "            \"experiment\": rel_parts[1] if len(rel_parts) > 1 else \"\",\n",
    "            \"run\": run_name,\n",
    "            \"run_index\": run_index,\n",
    "            \"nnodes\": nnodes,\n",
    "            \"chfs_chunk_size\": cmd_params.get(\"chfs_chunk_size\"),\n",
    "        }\n",
    "        \n",
    "        began = data.get(\"Began\", \"\")\n",
    "        finished = data.get(\"Finished\", \"\")\n",
    "        \n",
    "        for summary in data.get(\"summary\", []) or []:\n",
    "            record = base | {\n",
    "                \"command\": command,\n",
    "                \"began\": began,\n",
    "                \"finished\": finished,\n",
    "                \"operation\": summary.get(\"operation\"),\n",
    "                \"bw_max_mib\": parse_number(summary.get(\"bwMaxMIB\")),\n",
    "                \"bw_min_mib\": parse_number(summary.get(\"bwMinMIB\")),\n",
    "                \"bw_mean_mib\": parse_number(summary.get(\"bwMeanMIB\")),\n",
    "                \"bw_std_mib\": parse_number(summary.get(\"bwStdMIB\")),\n",
    "                \"ops_max\": parse_number(summary.get(\"OPsMax\")),\n",
    "                \"ops_min\": parse_number(summary.get(\"OPsMin\")),\n",
    "                \"ops_mean\": parse_number(summary.get(\"OPsMean\")),\n",
    "                \"ops_std\": parse_number(summary.get(\"OPsSD\")),\n",
    "                \"mean_time\": parse_number(summary.get(\"MeanTime\")),\n",
    "                \"xsize_mib\": parse_number(summary.get(\"xsizeMiB\")),\n",
    "                \"block_size_bytes\": parse_number(summary.get(\"blockSize\")),\n",
    "                \"transfer_size_bytes\": parse_number(summary.get(\"transferSize\")),\n",
    "                \"segment_count\": summary.get(\"segmentCount\"),\n",
    "                \"num_tasks\": summary.get(\"numTasks\"),\n",
    "                \"tasks_per_node\": summary.get(\"tasksPerNode\"),\n",
    "                \"repetitions\": summary.get(\"repetitions\"),\n",
    "                \"file_per_proc\": summary.get(\"filePerProc\"),\n",
    "                \"transfer_size_str\": cmd_params.get(\"transfer_size_str\", \"\"),\n",
    "                \"block_size_str\": cmd_params.get(\"block_size_str\", \"\"),\n",
    "            }\n",
    "            summary_records.append(record)\n",
    "            \n",
    "        for test in data.get(\"tests\", []) or []:\n",
    "            parameters = test.get(\"Parameters\", {}) or {}\n",
    "            options = test.get(\"Options\", {}) or {}\n",
    "            results = test.get(\"Results\", []) or []\n",
    "            \n",
    "            for result in results:\n",
    "                if result.get(\"access\") == \"remove\":\n",
    "                    continue\n",
    "                detail_record = base | {\n",
    "                    \"command\": command,\n",
    "                    \"test_id\": test.get(\"TestID\"),\n",
    "                    \"start_time\": test.get(\"StartTime\"),\n",
    "                    \"path\": test.get(\"Path\"),\n",
    "                    \"operation\": result.get(\"access\"),\n",
    "                    \"bw_mib\": parse_number(result.get(\"bwMiB\")),\n",
    "                    \"iops\": parse_number(result.get(\"iops\")),\n",
    "                    \"latency\": parse_number(result.get(\"latency\")),\n",
    "                    \"open_time\": parse_number(result.get(\"openTime\")),\n",
    "                    \"transfer_time\": parse_number(result.get(\"wrRdTime\")),\n",
    "                    \"close_time\": parse_number(result.get(\"closeTime\")),\n",
    "                    \"total_time\": parse_number(result.get(\"totalTime\")),\n",
    "                    \"block_kib\": parse_number(result.get(\"blockKiB\")),\n",
    "                    \"xfer_kib\": parse_number(result.get(\"xferKiB\")),\n",
    "                    \"segment_count\": parameters.get(\"segmentCount\"),\n",
    "                    \"transfer_size_bytes\": parameters.get(\"transferSize\"),\n",
    "                    \"block_size_bytes\": parameters.get(\"blockSize\"),\n",
    "                    \"num_tasks\": options.get(\"tasks\"),\n",
    "                    \"nodes\": options.get(\"nodes\"),\n",
    "                    \"tasks_per_node\": options.get(\"clients per node\"),\n",
    "                    \"transfer_size_str\": cmd_params.get(\"transfer_size_str\", \"\"),\n",
    "                    \"block_size_str\": cmd_params.get(\"block_size_str\", \"\"),\n",
    "                    \"file_per_proc\": cmd_params.get(\"file_per_proc\", 0),\n",
    "                }\n",
    "                detail_records.append(detail_record)\n",
    "                \n",
    "    summary_df = pl.DataFrame(summary_records) if summary_records else pl.DataFrame([])\n",
    "    \n",
    "    if not summary_df.is_empty():\n",
    "        summary_df = (\n",
    "            summary_df\n",
    "            .with_columns(\n",
    "                pl.col(\"num_tasks\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"tasks_per_node\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"repetitions\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"file_per_proc\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"segment_count\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"nnodes\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"chfs_chunk_size\").cast(pl.Int64, strict=False),\n",
    "                (pl.col(\"block_size_bytes\") / (1024 ** 2)).alias(\"block_size_mib\"),\n",
    "                (pl.col(\"transfer_size_bytes\") / (1024 ** 2)).alias(\"transfer_size_mib\"),\n",
    "                (pl.col(\"bw_mean_mib\") / 1024.0).alias(\"bw_mean_gib\"),\n",
    "                (pl.col(\"bw_max_mib\") / 1024.0).alias(\"bw_max_gib\"),\n",
    "                (pl.col(\"bw_min_mib\") / 1024.0).alias(\"bw_min_gib\"),\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(pl.col(\"file_per_proc\") == 1)\n",
    "                .then(pl.lit(\"File-per-Process\"))\n",
    "                .otherwise(pl.lit(\"Shared File\"))\n",
    "                .alias(\"access_mode\"),\n",
    "            )\n",
    "            .sort([\"backend\", \"experiment\", \"run\", \"run_index\", \"operation\"])\n",
    "        )\n",
    "        \n",
    "    detail_df = pl.DataFrame(detail_records) if detail_records else pl.DataFrame([])\n",
    "    \n",
    "    if not detail_df.is_empty():\n",
    "        detail_df = (\n",
    "            detail_df\n",
    "            .with_columns(\n",
    "                pl.col(\"num_tasks\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"nodes\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"tasks_per_node\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"nnodes\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"chfs_chunk_size\").cast(pl.Int64, strict=False),\n",
    "                (pl.col(\"block_kib\") / 1024.0).alias(\"block_mib\"),\n",
    "                (pl.col(\"xfer_kib\") / 1024.0).alias(\"xfer_mib\"),\n",
    "                (pl.col(\"transfer_size_bytes\") / (1024 ** 2)).alias(\"transfer_size_mib\"),\n",
    "                (pl.col(\"block_size_bytes\") / (1024 ** 2)).alias(\"block_size_mib\"),\n",
    "                (pl.col(\"bw_mib\") / 1024.0).alias(\"bw_gib\"),\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(pl.col(\"file_per_proc\") == 1)\n",
    "                .then(pl.lit(\"File-per-Process\"))\n",
    "                .otherwise(pl.lit(\"Shared File\"))\n",
    "                .alias(\"access_mode\"),\n",
    "            )\n",
    "            .sort([\"backend\", \"experiment\", \"run\", \"run_index\", \"operation\", \"test_id\"])\n",
    "        )\n",
    "        \n",
    "    return summary_df, detail_df\n",
    "\n",
    "ior_summary_df, ior_detail_df = load_ior_json(results_root)\n",
    "\n",
    "print(f\"Loaded {len(ior_summary_df)} summary records and {len(ior_detail_df)} detail records\")\n",
    "\n",
    "if not ior_summary_df.is_empty():\n",
    "    print(f\"\\nExperiments: {ior_summary_df['experiment'].unique().to_list()}\")\n",
    "    display(ior_summary_df.head(10).to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "select-experiment",
   "metadata": {},
   "source": [
    "## Select Experiments\n",
    "\n",
    "分析対象の実験を選択します。`results/chfs/` 以下のディレクトリ名を指定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-experiment-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_available_experiments(results_root: Path) -> list[str]:\n",
    "    \"\"\"List available experiment directories under results/chfs/.\"\"\"\n",
    "    chfs_dir = results_root / \"chfs\"\n",
    "    if not chfs_dir.exists():\n",
    "        return []\n",
    "    experiments = [\n",
    "        d.name for d in sorted(chfs_dir.iterdir(), reverse=True)\n",
    "        if d.is_dir() and not d.name.startswith(\".\")\n",
    "    ]\n",
    "    return experiments\n",
    "\n",
    "available_experiments = list_available_experiments(results_root)\n",
    "print(\"Available experiments in results/chfs/:\")\n",
    "for i, exp in enumerate(available_experiments):\n",
    "    print(f\"  [{i}] {exp}\")\n",
    "\n",
    "if SELECTED_EXPERIMENTS is None:\n",
    "    SELECTED_EXPERIMENTS = [available_experiments[0]] if available_experiments else []\n",
    "    print(f\"\\n(Auto-selected latest experiment)\")\n",
    "elif isinstance(SELECTED_EXPERIMENTS, str):\n",
    "    SELECTED_EXPERIMENTS = [SELECTED_EXPERIMENTS]\n",
    "\n",
    "valid_experiments = []\n",
    "for exp in SELECTED_EXPERIMENTS:\n",
    "    if exp in available_experiments:\n",
    "        valid_experiments.append(exp)\n",
    "    else:\n",
    "        print(f\"  Warning: '{exp}' not found in results/chfs/\")\n",
    "\n",
    "SELECTED_EXPERIMENTS = valid_experiments\n",
    "print(f\"\\nSelected experiments ({len(SELECTED_EXPERIMENTS)}):\")\n",
    "for exp in SELECTED_EXPERIMENTS:\n",
    "    print(f\"  - {exp}\")\n",
    "\n",
    "if SELECTED_EXPERIMENTS:\n",
    "    filtered_summary_df = ior_summary_df.filter(\n",
    "        pl.col(\"experiment\").is_in(SELECTED_EXPERIMENTS)\n",
    "    )\n",
    "    filtered_detail_df = ior_detail_df.filter(\n",
    "        pl.col(\"experiment\").is_in(SELECTED_EXPERIMENTS)\n",
    "    )\n",
    "    print(f\"\\nFiltered data: {len(filtered_summary_df)} summary records, {len(filtered_detail_df)} detail records\")\n",
    "else:\n",
    "    filtered_summary_df = ior_summary_df\n",
    "    filtered_detail_df = ior_detail_df\n",
    "    print(\"\\nNo experiments selected. Using all data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11486486",
   "metadata": {},
   "source": [
    "## Summary Overview\n",
    "\n",
    "IOR JSONサマリを実験 x 実行 x 操作単位で整形したテーブルを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtered_summary_df.is_empty():\n",
    "    print(\"No IOR summary rows to show.\")\n",
    "else:\n",
    "    overview = (\n",
    "        filtered_summary_df\n",
    "        .select(\n",
    "            \"backend\",\n",
    "            \"experiment\",\n",
    "            \"run\",\n",
    "            \"run_index\",\n",
    "            \"operation\",\n",
    "            \"access_mode\",\n",
    "            \"nnodes\",\n",
    "            \"block_size_str\",\n",
    "            \"transfer_size_str\",\n",
    "            \"bw_mean_mib\",\n",
    "            \"bw_mean_gib\",\n",
    "            \"mean_time\",\n",
    "            \"num_tasks\",\n",
    "            \"tasks_per_node\",\n",
    "        )\n",
    "        .sort([\"backend\", \"experiment\", \"run\", \"run_index\", \"operation\"])\n",
    "    )\n",
    "    display(overview.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "node-comparison",
   "metadata": {},
   "source": [
    "## Node Count Comparison (Scalability)\n",
    "\n",
    "ノード数ごとの帯域を比較し、スケーラビリティを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "node-comparison-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtered_detail_df.is_empty() or not SELECTED_EXPERIMENTS:\n",
    "    print(\"No data to plot.\")\n",
    "else:\n",
    "    if len(SELECTED_EXPERIMENTS) == 1:\n",
    "        exp_df = filtered_detail_df.filter(pl.col(\"experiment\") == SELECTED_EXPERIMENTS[0])\n",
    "        experiment_label = SELECTED_EXPERIMENTS[0]\n",
    "    else:\n",
    "        exp_df = filtered_detail_df\n",
    "        experiment_label = f\"{len(SELECTED_EXPERIMENTS)} experiments\"\n",
    "    \n",
    "    node_counts = sorted(exp_df[\"nnodes\"].unique().drop_nulls().to_list())\n",
    "    print(f\"Node counts in experiment: {node_counts}\")\n",
    "    \n",
    "    if len(node_counts) < 2:\n",
    "        print(\"Need at least 2 different node counts for comparison.\")\n",
    "    else:\n",
    "        node_bw = (\n",
    "            exp_df\n",
    "            .group_by([\"nnodes\", \"operation\", \"access_mode\"])\n",
    "            .agg([\n",
    "                pl.col(\"bw_gib\").max().alias(\"bw_gib_max\"),\n",
    "                pl.len().alias(\"samples\"),\n",
    "            ])\n",
    "            .sort(\"nnodes\")\n",
    "        ).to_pandas()\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        colors = {'File-per-Process': '#2196F3', 'Shared File': '#FF9800'}\n",
    "        markers = {'File-per-Process': 'o', 'Shared File': 's'}\n",
    "        \n",
    "        for ax, operation in zip(axes, ['write', 'read']):\n",
    "            op_df = node_bw[node_bw['operation'] == operation]\n",
    "            \n",
    "            for mode in ['File-per-Process', 'Shared File']:\n",
    "                mode_df = op_df[op_df['access_mode'] == mode]\n",
    "                if mode_df.empty:\n",
    "                    continue\n",
    "                    \n",
    "                ax.plot(\n",
    "                    mode_df['nnodes'],\n",
    "                    mode_df['bw_gib_max'],\n",
    "                    marker=markers[mode],\n",
    "                    markersize=10,\n",
    "                    linewidth=2,\n",
    "                    label=mode,\n",
    "                    color=colors[mode],\n",
    "                )\n",
    "                \n",
    "                for _, row in mode_df.iterrows():\n",
    "                    ax.annotate(\n",
    "                        f\"{row['bw_gib_max']:.1f}\",\n",
    "                        (row['nnodes'], row['bw_gib_max']),\n",
    "                        textcoords=\"offset points\",\n",
    "                        xytext=(0, 10),\n",
    "                        ha='center',\n",
    "                        fontsize=9,\n",
    "                    )\n",
    "            \n",
    "            ax.set_xlabel('Number of Nodes')\n",
    "            ax.set_ylabel('Bandwidth (GiB/s)')\n",
    "            ax.set_title(f'{operation.capitalize()} Bandwidth by Node Count (Max)')\n",
    "            ax.legend(loc='upper left')\n",
    "            ax.grid(alpha=0.3, linestyle='--')\n",
    "            ax.set_xticks(node_counts)\n",
    "        \n",
    "        fig.suptitle(f'CHFS: {experiment_label}\\nNode Scalability (Best Performance)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        save(fig, f\"chfs_node_scalability_{slugify(experiment_label)}\")\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "client-ppn-comparison",
   "metadata": {},
   "source": [
    "## Client PPN Comparison\n",
    "\n",
    "クライアント側のPPN (processes per node) による帯域の違いを比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "client-ppn-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtered_detail_df.is_empty() or not SELECTED_EXPERIMENTS:\n",
    "    print(\"No data to plot.\")\n",
    "else:\n",
    "    if len(SELECTED_EXPERIMENTS) == 1:\n",
    "        exp_df = filtered_detail_df.filter(pl.col(\"experiment\") == SELECTED_EXPERIMENTS[0])\n",
    "        experiment_label = SELECTED_EXPERIMENTS[0]\n",
    "    else:\n",
    "        exp_df = filtered_detail_df\n",
    "        experiment_label = f\"{len(SELECTED_EXPERIMENTS)} experiments\"\n",
    "    \n",
    "    ppn_values = sorted(exp_df[\"tasks_per_node\"].unique().drop_nulls().to_list())\n",
    "    print(f\"Client PPN values: {ppn_values}\")\n",
    "    \n",
    "    if len(ppn_values) < 2:\n",
    "        print(\"Need at least 2 different client PPN values for comparison.\")\n",
    "    else:\n",
    "        ppn_bw = (\n",
    "            exp_df\n",
    "            .group_by([\"tasks_per_node\", \"operation\", \"access_mode\", \"nnodes\"])\n",
    "            .agg([\n",
    "                pl.col(\"bw_gib\").max().alias(\"bw_gib_max\"),\n",
    "                pl.col(\"num_tasks\").first().alias(\"num_tasks\"),\n",
    "            ])\n",
    "            .sort(\"tasks_per_node\")\n",
    "        ).to_pandas()\n",
    "        \n",
    "        node_counts = sorted(ppn_bw['nnodes'].dropna().unique())\n",
    "        \n",
    "        for nnodes in node_counts:\n",
    "            node_df = ppn_bw[ppn_bw['nnodes'] == nnodes]\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "            \n",
    "            colors = {'File-per-Process': '#2196F3', 'Shared File': '#FF9800'}\n",
    "            \n",
    "            for ax, operation in zip(axes, ['write', 'read']):\n",
    "                op_df = node_df[node_df['operation'] == operation]\n",
    "                ppn_list = sorted(op_df['tasks_per_node'].unique())\n",
    "                \n",
    "                width = 0.35\n",
    "                x = range(len(ppn_list))\n",
    "                \n",
    "                for i, mode in enumerate(['File-per-Process', 'Shared File']):\n",
    "                    mode_df = op_df[op_df['access_mode'] == mode]\n",
    "                    if mode_df.empty:\n",
    "                        continue\n",
    "                    mode_df = mode_df.set_index('tasks_per_node').reindex(ppn_list)\n",
    "                    \n",
    "                    offset = -width/2 if i == 0 else width/2\n",
    "                    ax.bar(\n",
    "                        [xi + offset for xi in x],\n",
    "                        mode_df['bw_gib_max'].fillna(0),\n",
    "                        width=width,\n",
    "                        label=mode,\n",
    "                        color=colors[mode],\n",
    "                        edgecolor='black',\n",
    "                        linewidth=0.5,\n",
    "                    )\n",
    "                \n",
    "                ax.set_xlabel('Client PPN (processes per node)')\n",
    "                ax.set_ylabel('Bandwidth (GiB/s)')\n",
    "                ax.set_title(f'{operation.capitalize()} Bandwidth (Max)')\n",
    "                ax.set_xticks(x)\n",
    "                ax.set_xticklabels([int(p) for p in ppn_list])\n",
    "                ax.legend(loc='upper left')\n",
    "                ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "                \n",
    "                for container in ax.containers:\n",
    "                    if hasattr(container, 'patches'):\n",
    "                        ax.bar_label(container, fmt='%.1f', padding=3, fontsize=8)\n",
    "            \n",
    "            fig.suptitle(f'CHFS: {experiment_label} ({int(nnodes)} nodes)\\nClient PPN Comparison', fontsize=14, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            save(fig, f\"chfs_client_ppn_{slugify(experiment_label)}_{int(nnodes)}nodes\")\n",
    "            plt.show()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4df6a2",
   "metadata": {},
   "source": [
    "## Bandwidth by Block Size\n",
    "\n",
    "ブロックサイズ別のRead/Write帯域を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1eb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtered_detail_df.is_empty() or not SELECTED_EXPERIMENTS:\n",
    "    print(\"No data to plot.\")\n",
    "else:\n",
    "    if len(SELECTED_EXPERIMENTS) == 1:\n",
    "        exp_df = filtered_detail_df.filter(pl.col(\"experiment\") == SELECTED_EXPERIMENTS[0])\n",
    "        experiment_label = SELECTED_EXPERIMENTS[0]\n",
    "    else:\n",
    "        exp_df = filtered_detail_df\n",
    "        experiment_label = f\"{len(SELECTED_EXPERIMENTS)} experiments\"\n",
    "    \n",
    "    for access_mode in [\"File-per-Process\", \"Shared File\"]:\n",
    "        mode_df = exp_df.filter(pl.col(\"access_mode\") == access_mode)\n",
    "        if mode_df.is_empty():\n",
    "            continue\n",
    "            \n",
    "        grouped = (\n",
    "            mode_df\n",
    "            .group_by([\"block_size_str\", \"operation\"])\n",
    "            .agg([\n",
    "                pl.col(\"bw_gib\").max().alias(\"bw_gib_max\"),\n",
    "            ])\n",
    "            .sort(\"block_size_str\")\n",
    "        )\n",
    "        \n",
    "        pivot_df = grouped.pivot(\n",
    "            values=\"bw_gib_max\",\n",
    "            index=\"block_size_str\",\n",
    "            on=\"operation\"\n",
    "        ).to_pandas().set_index(\"block_size_str\")\n",
    "        \n",
    "        size_order = ['64m', '256m', '512m', '1g', '2g', '4g']\n",
    "        pivot_df = pivot_df.reindex([s for s in size_order if s in pivot_df.index])\n",
    "        \n",
    "        if pivot_df.empty:\n",
    "            continue\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        x = range(len(pivot_df))\n",
    "        width = 0.35\n",
    "        \n",
    "        colors = {'write': '#2196F3', 'read': '#4CAF50'}\n",
    "        \n",
    "        if 'write' in pivot_df.columns:\n",
    "            ax.bar([i - width/2 for i in x], pivot_df['write'], width, \n",
    "                   label='Write', color=colors['write'], edgecolor='black', linewidth=0.5)\n",
    "        if 'read' in pivot_df.columns:\n",
    "            ax.bar([i + width/2 for i in x], pivot_df['read'], width,\n",
    "                   label='Read', color=colors['read'], edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        ax.set_xlabel('Block Size')\n",
    "        ax.set_ylabel('Bandwidth (GiB/s)')\n",
    "        ax.set_title(f'CHFS: {experiment_label} - {access_mode}\\nBandwidth by Block Size (Max)')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(pivot_df.index)\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        for bars in ax.containers:\n",
    "            ax.bar_label(bars, fmt='%.1f', padding=3, fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save(fig, f\"chfs_bandwidth_by_blocksize_{slugify(experiment_label)}_{slugify(access_mode)}\")\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scalability",
   "metadata": {},
   "source": [
    "## Scalability Analysis\n",
    "\n",
    "ノード数・プロセス数に対するスケーラビリティを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scalability-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtered_detail_df.is_empty() or not SELECTED_EXPERIMENTS:\n",
    "    print(\"No data to plot.\")\n",
    "else:\n",
    "    if len(SELECTED_EXPERIMENTS) == 1:\n",
    "        exp_df = filtered_detail_df.filter(pl.col(\"experiment\") == SELECTED_EXPERIMENTS[0])\n",
    "        experiment_label = SELECTED_EXPERIMENTS[0]\n",
    "    else:\n",
    "        exp_df = filtered_detail_df\n",
    "        experiment_label = f\"{len(SELECTED_EXPERIMENTS)} experiments\"\n",
    "    \n",
    "    scalability = (\n",
    "        exp_df\n",
    "        .group_by([\"num_tasks\", \"operation\", \"access_mode\"])\n",
    "        .agg([\n",
    "            pl.col(\"bw_gib\").max().alias(\"bw_gib_max\"),\n",
    "            pl.col(\"nnodes\").first().alias(\"nodes\"),\n",
    "        ])\n",
    "        .sort(\"num_tasks\")\n",
    "    )\n",
    "    \n",
    "    if scalability.is_empty():\n",
    "        print(\"No scalability data available.\")\n",
    "    else:\n",
    "        pdf = scalability.to_pandas()\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        for ax, operation in zip(axes, ['write', 'read']):\n",
    "            op_df = pdf[pdf['operation'] == operation]\n",
    "            \n",
    "            for access_mode, marker, color in [('File-per-Process', 'o', '#2196F3'), ('Shared File', 's', '#FF9800')]:\n",
    "                mode_df = op_df[op_df['access_mode'] == access_mode]\n",
    "                if mode_df.empty:\n",
    "                    continue\n",
    "                ax.plot(\n",
    "                    mode_df['num_tasks'],\n",
    "                    mode_df['bw_gib_max'],\n",
    "                    marker=marker,\n",
    "                    markersize=8,\n",
    "                    linewidth=2,\n",
    "                    label=access_mode,\n",
    "                    color=color,\n",
    "                )\n",
    "            \n",
    "            ax.set_xlabel('Number of Tasks (MPI Processes)')\n",
    "            ax.set_ylabel('Bandwidth (GiB/s)')\n",
    "            ax.set_title(f'{operation.capitalize()} Bandwidth Scalability (Max)')\n",
    "            ax.legend()\n",
    "            ax.grid(alpha=0.3, linestyle='--')\n",
    "            ax.set_xscale('log', base=2)\n",
    "        \n",
    "        fig.suptitle(f'CHFS: {experiment_label} - Scalability Analysis', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        save(fig, f\"chfs_scalability_{slugify(experiment_label)}\")\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "## Read vs Write Comparison\n",
    "\n",
    "Read/Writeの帯域比較を散布図で可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtered_detail_df.is_empty() or not SELECTED_EXPERIMENTS:\n",
    "    print(\"No data to plot.\")\n",
    "else:\n",
    "    if len(SELECTED_EXPERIMENTS) == 1:\n",
    "        exp_df = filtered_detail_df.filter(pl.col(\"experiment\") == SELECTED_EXPERIMENTS[0])\n",
    "        experiment_label = SELECTED_EXPERIMENTS[0]\n",
    "    else:\n",
    "        exp_df = filtered_detail_df\n",
    "        experiment_label = f\"{len(SELECTED_EXPERIMENTS)} experiments\"\n",
    "    \n",
    "    write_df = exp_df.filter(pl.col(\"operation\") == \"write\").select(\n",
    "        \"run_index\", \"access_mode\", \"block_size_str\", \"num_tasks\",\n",
    "        pl.col(\"bw_gib\").alias(\"write_bw_gib\")\n",
    "    )\n",
    "    read_df = exp_df.filter(pl.col(\"operation\") == \"read\").select(\n",
    "        \"run_index\", \"access_mode\", \"block_size_str\", \"num_tasks\",\n",
    "        pl.col(\"bw_gib\").alias(\"read_bw_gib\")\n",
    "    )\n",
    "    \n",
    "    merged = write_df.join(\n",
    "        read_df,\n",
    "        on=[\"run_index\", \"access_mode\", \"block_size_str\", \"num_tasks\"],\n",
    "        how=\"inner\"\n",
    "    ).to_pandas()\n",
    "    \n",
    "    if merged.empty:\n",
    "        print(\"No paired write/read data available.\")\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        \n",
    "        colors = {'File-per-Process': '#2196F3', 'Shared File': '#FF9800'}\n",
    "        markers = {'File-per-Process': 'o', 'Shared File': 's'}\n",
    "        \n",
    "        for mode in merged['access_mode'].unique():\n",
    "            mode_df = merged[merged['access_mode'] == mode]\n",
    "            ax.scatter(\n",
    "                mode_df['write_bw_gib'],\n",
    "                mode_df['read_bw_gib'],\n",
    "                c=colors.get(mode, 'gray'),\n",
    "                marker=markers.get(mode, 'o'),\n",
    "                s=100,\n",
    "                alpha=0.7,\n",
    "                edgecolors='black',\n",
    "                linewidths=0.5,\n",
    "                label=mode\n",
    "            )\n",
    "        \n",
    "        max_val = max(merged['write_bw_gib'].max(), merged['read_bw_gib'].max()) * 1.1\n",
    "        ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.3, label='Read = Write')\n",
    "        \n",
    "        ax.set_xlabel('Write Bandwidth (GiB/s)')\n",
    "        ax.set_ylabel('Read Bandwidth (GiB/s)')\n",
    "        ax.set_title(f'CHFS: {experiment_label}\\nRead vs Write Bandwidth')\n",
    "        ax.legend()\n",
    "        ax.grid(alpha=0.3, linestyle='--')\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save(fig, f\"chfs_read_vs_write_{slugify(experiment_label)}\")\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-table",
   "metadata": {},
   "source": [
    "## Summary Statistics Table\n",
    "\n",
    "実験の統計サマリを表形式で表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtered_detail_df.is_empty() or not SELECTED_EXPERIMENTS:\n",
    "    print(\"No data available.\")\n",
    "else:\n",
    "    exp_df = filtered_detail_df\n",
    "    \n",
    "    stats = (\n",
    "        exp_df\n",
    "        .group_by([\"experiment\", \"access_mode\", \"operation\", \"block_size_str\"])\n",
    "        .agg([\n",
    "            pl.col(\"bw_gib\").mean().round(2).alias(\"Mean (GiB/s)\"),\n",
    "            pl.col(\"bw_gib\").max().round(2).alias(\"Max (GiB/s)\"),\n",
    "            pl.col(\"bw_gib\").min().round(2).alias(\"Min (GiB/s)\"),\n",
    "            pl.col(\"bw_gib\").std().round(2).alias(\"Std (GiB/s)\"),\n",
    "            pl.len().alias(\"Samples\"),\n",
    "        ])\n",
    "        .sort([\"experiment\", \"access_mode\", \"operation\", \"block_size_str\"])\n",
    "    )\n",
    "    \n",
    "    experiment_label = SELECTED_EXPERIMENTS[0] if len(SELECTED_EXPERIMENTS) == 1 else f\"{len(SELECTED_EXPERIMENTS)} experiments\"\n",
    "    print(f\"\\nCHFS: {experiment_label} - Summary Statistics\\n\")\n",
    "    display(stats.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505a1a5",
   "metadata": {},
   "source": [
    "## Export Processed Data\n",
    "\n",
    "整形済みのサマリと詳細データをJSONとして保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8eb1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtered_summary_df.is_empty() and filtered_detail_df.is_empty():\n",
    "    print(\"No IOR results to export.\")\n",
    "else:\n",
    "    experiment_suffix = \"_\".join(slugify(e) for e in SELECTED_EXPERIMENTS) if SELECTED_EXPERIMENTS else \"all\"\n",
    "    \n",
    "    if not filtered_summary_df.is_empty():\n",
    "        summary_out = DATA_DIR / f\"chfs_ior_summary_{experiment_suffix}.json\"\n",
    "        summary_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "        summary_out.write_text(\n",
    "            json.dumps(filtered_summary_df.to_pandas().to_dict(orient=\"records\"), ensure_ascii=False, indent=2)\n",
    "        )\n",
    "        print(f\"Wrote {summary_out}\")\n",
    "    else:\n",
    "        print(\"No summary records to export.\")\n",
    "        \n",
    "    if not filtered_detail_df.is_empty():\n",
    "        detail_out = DATA_DIR / f\"chfs_ior_detail_{experiment_suffix}.json\"\n",
    "        detail_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "        detail_out.write_text(\n",
    "            json.dumps(filtered_detail_df.to_pandas().to_dict(orient=\"records\"), ensure_ascii=False, indent=2)\n",
    "        )\n",
    "        print(f\"Wrote {detail_out}\")\n",
    "    else:\n",
    "        print(\"No detailed records to export.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
