{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35911d5",
   "metadata": {},
   "source": [
    "# BenchFS IOR Result Visualizer\n",
    "\n",
    "`results/benchfs/*/ior_results/ior_result_*.json` から IOR のサマリ JSON を読み込み、操作別の帯域やレイテンシを可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b56b8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'2022.2.1 (Python 3.9.13)' でセルを実行するには、 ipykernel パッケージが必要です。\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Python 環境の作成</a> および必要なパッケージ。\n",
      "\u001b[1;31mまたは、次のコマンドを使用して 'ipykernel' をインストールします: 'conda install -n 2022.2.1 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from IPython.display import display\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "pl.Config.set_tbl_rows(100)\n",
    "\n",
    "DATA_DIR = (Path.cwd() / \"processed\" / \"benchfsd\").resolve()\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR = (Path.cwd() / \"fig\" / \"benchfsd\").resolve()\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save(fig, name: str) -> None:\n",
    "    for ext in (\"png\", \"pdf\"):\n",
    "        fig.savefig(FIG_DIR / f\"{name}.{ext}\", bbox_inches=\"tight\")\n",
    "\n",
    "def comma_formatter(value, _):\n",
    "    return f\"{value:,.0f}\"\n",
    "\n",
    "def slugify(value: str) -> str:\n",
    "    cleaned = re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", value)\n",
    "    return cleaned.strip(\"_\") or \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb50f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_results_root() -> Path:\n",
    "    candidates = [\n",
    "        Path(\"results\"),\n",
    "        Path(\"..\") / \"results\",\n",
    "        Path(\"../..\") / \"results\",\n",
    "    ]\n",
    "    for candidate in candidates:\n",
    "        if candidate.exists():\n",
    "            return candidate.resolve()\n",
    "    raise FileNotFoundError(\"results ディレクトリが見つかりません。ノートブックの位置を確認してください。\")\n",
    "\n",
    "results_root = resolve_results_root()\n",
    "print(f\"Using results directory: {results_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d77ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "IOR_JSON_PATTERN = re.compile(r\"ior_result_(\\d+)\\.json$\")\n",
    "\n",
    "def parse_number(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, (int, float)):\n",
    "        return float(value)\n",
    "    if isinstance(value, str):\n",
    "        cleaned = value.replace(\",\", \"\").strip()\n",
    "        if cleaned == \"\":\n",
    "            return None\n",
    "        try:\n",
    "            return float(cleaned)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def bytes_to_mib(value):\n",
    "    number = parse_number(value)\n",
    "    return number / (1024 ** 2) if number is not None else None\n",
    "\n",
    "def kib_to_mib(value):\n",
    "    number = parse_number(value)\n",
    "    return number / 1024.0 if number is not None else None\n",
    "\n",
    "def load_ior_json(root: Path) -> tuple[pl.DataFrame, pl.DataFrame]:\n",
    "    summary_records = []\n",
    "    detail_records = []\n",
    "    for path in sorted(root.glob(\"**/ior_results/ior_result_*.json\")):\n",
    "        try:\n",
    "            data = json.loads(path.read_text())\n",
    "        except (OSError, json.JSONDecodeError) as exc:\n",
    "            print(f\"⚠️ Failed to parse {path}: {exc}\")\n",
    "            continue\n",
    "        rel_parts = path.relative_to(root).parts\n",
    "        match = IOR_JSON_PATTERN.search(path.name)\n",
    "        run_index = int(match.group(1)) if match else None\n",
    "        base = {\n",
    "            \"ior_file\": str(path.relative_to(root)),\n",
    "            \"collection\": \"/\".join(rel_parts[:-1]),\n",
    "            \"backend\": rel_parts[0] if len(rel_parts) > 0 else \"\",\n",
    "            \"experiment\": rel_parts[1] if len(rel_parts) > 1 else \"\",\n",
    "            \"run\": rel_parts[2] if len(rel_parts) > 2 else \"\",\n",
    "            \"run_index\": run_index,\n",
    "        }\n",
    "        command = data.get(\"Command line\", \"\")\n",
    "        began = data.get(\"Began\", \"\")\n",
    "        finished = data.get(\"Finished\", \"\")\n",
    "        for summary in data.get(\"summary\", []) or []:\n",
    "            record = base | {\n",
    "                \"command\": command,\n",
    "                \"began\": began,\n",
    "                \"finished\": finished,\n",
    "                \"operation\": summary.get(\"operation\"),\n",
    "                \"bw_max_mib\": parse_number(summary.get(\"bwMaxMIB\")),\n",
    "                \"bw_min_mib\": parse_number(summary.get(\"bwMinMIB\")),\n",
    "                \"bw_mean_mib\": parse_number(summary.get(\"bwMeanMIB\")),\n",
    "                \"bw_std_mib\": parse_number(summary.get(\"bwStdMIB\")),\n",
    "                \"ops_max\": parse_number(summary.get(\"OPsMax\")),\n",
    "                \"ops_min\": parse_number(summary.get(\"OPsMin\")),\n",
    "                \"ops_mean\": parse_number(summary.get(\"OPsMean\")),\n",
    "                \"ops_std\": parse_number(summary.get(\"OPsSD\")),\n",
    "                \"mean_time\": parse_number(summary.get(\"MeanTime\")),\n",
    "                \"xsize_mib\": parse_number(summary.get(\"xsizeMiB\")),\n",
    "                \"block_size_bytes\": parse_number(summary.get(\"blockSize\")),\n",
    "                \"transfer_size_bytes\": parse_number(summary.get(\"transferSize\")),\n",
    "                \"segment_count\": summary.get(\"segmentCount\"),\n",
    "                \"num_tasks\": summary.get(\"numTasks\"),\n",
    "                \"tasks_per_node\": summary.get(\"tasksPerNode\"),\n",
    "                \"repetitions\": summary.get(\"repetitions\"),\n",
    "                \"file_per_proc\": summary.get(\"filePerProc\"),\n",
    "            }\n",
    "            summary_records.append(record)\n",
    "        for test in data.get(\"tests\", []) or []:\n",
    "            parameters = test.get(\"Parameters\", {}) or {}\n",
    "            results = test.get(\"Results\", []) or []\n",
    "            for result in results:\n",
    "                detail_record = base | {\n",
    "                    \"command\": command,\n",
    "                    \"test_id\": test.get(\"TestID\"),\n",
    "                    \"start_time\": test.get(\"StartTime\"),\n",
    "                    \"path\": test.get(\"Path\"),\n",
    "                    \"operation\": result.get(\"access\"),\n",
    "                    \"bw_mib\": parse_number(result.get(\"bwMiB\")),\n",
    "                    \"iops\": parse_number(result.get(\"iops\")),\n",
    "                    \"latency\": parse_number(result.get(\"latency\")),\n",
    "                    \"open_time\": parse_number(result.get(\"openTime\")),\n",
    "                    \"transfer_time\": parse_number(result.get(\"wrRdTime\")),\n",
    "                    \"close_time\": parse_number(result.get(\"closeTime\")),\n",
    "                    \"total_time\": parse_number(result.get(\"totalTime\")),\n",
    "                    \"block_kib\": parse_number(result.get(\"blockKiB\")),\n",
    "                    \"xfer_kib\": parse_number(result.get(\"xferKiB\")),\n",
    "                    \"segment_count\": parameters.get(\"segmentCount\"),\n",
    "                    \"transfer_size_bytes\": parameters.get(\"transferSize\"),\n",
    "                    \"block_size_bytes\": parameters.get(\"blockSize\"),\n",
    "                }\n",
    "                detail_records.append(detail_record)\n",
    "    summary_df = pl.DataFrame(summary_records) if summary_records else pl.DataFrame([])\n",
    "    if not summary_df.is_empty():\n",
    "        summary_df = (\n",
    "            summary_df\n",
    "            .with_columns(\n",
    "                pl.col(\"num_tasks\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"tasks_per_node\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"repetitions\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"file_per_proc\").cast(pl.Int64, strict=False),\n",
    "                pl.col(\"segment_count\").cast(pl.Int64, strict=False),\n",
    "                (pl.col(\"block_size_bytes\") / (1024 ** 2)).alias(\"block_size_mib\"),\n",
    "                (pl.col(\"transfer_size_bytes\") / (1024 ** 2)).alias(\"transfer_size_mib\"),\n",
    "                (pl.col(\"bw_mean_mib\") / 1024.0).alias(\"bw_mean_gib\"),\n",
    "                (pl.col(\"bw_max_mib\") / 1024.0).alias(\"bw_max_gib\"),\n",
    "                (pl.col(\"bw_min_mib\") / 1024.0).alias(\"bw_min_gib\"),\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(\n",
    "                    pl.col(\"block_size_mib\").is_not_null() & pl.col(\"transfer_size_mib\").is_not_null()\n",
    "                )\n",
    "                .then(\n",
    "                    pl.format(\n",
    "                        \"blk {0:.1f} MiB / xfer {1:.2f} MiB\",\n",
    "                        pl.col(\"block_size_mib\"),\n",
    "                        pl.col(\"transfer_size_mib\"),\n",
    "                    )\n",
    "                )\n",
    "                .otherwise(\"unknown\")\n",
    "                .alias(\"config\"),\n",
    "            )\n",
    "            .sort([\"backend\", \"experiment\", \"run\", \"run_index\", \"operation\"])\n",
    "        )\n",
    "    detail_df = pl.DataFrame(detail_records) if detail_records else pl.DataFrame([])\n",
    "    if not detail_df.is_empty():\n",
    "        detail_df = (\n",
    "            detail_df\n",
    "            .with_columns(\n",
    "                (pl.col(\"block_kib\") / 1024.0).alias(\"block_mib\"),\n",
    "                (pl.col(\"xfer_kib\") / 1024.0).alias(\"xfer_mib\"),\n",
    "                (pl.col(\"transfer_size_bytes\") / (1024 ** 2)).alias(\"transfer_size_mib\"),\n",
    "                (pl.col(\"block_size_bytes\") / (1024 ** 2)).alias(\"block_size_mib\"),\n",
    "            )\n",
    "            .sort([\"backend\", \"experiment\", \"run\", \"run_index\", \"operation\", \"test_id\"])\n",
    "        )\n",
    "    return summary_df, detail_df\n",
    "\n",
    "ior_summary_df, ior_detail_df = load_ior_json(results_root)\n",
    "if ior_summary_df.is_empty():\n",
    "    print(\"No ior_result_*.json files found under results.\")\n",
    "else:\n",
    "    display(ior_summary_df.head().to_pandas())\n",
    "if ior_detail_df.is_empty():\n",
    "    print(\"No detailed IOR test entries available.\")\n",
    "else:\n",
    "    display(ior_detail_df.head().to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11486486",
   "metadata": {},
   "source": [
    "## Summary Overview\n",
    "\n",
    "IOR JSONサマリを実験 × 実行 × 操作単位で整形したテーブルを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ior_summary_df.is_empty():\n",
    "    print(\"No IOR summary rows to show.\")\n",
    "else:\n",
    "    overview = (\n",
    "        ior_summary_df\n",
    "        .select(\n",
    "            \"backend\",\n",
    "            \"experiment\",\n",
    "            \"run\",\n",
    "            \"run_index\",\n",
    "            \"operation\",\n",
    "            \"config\",\n",
    "            \"bw_mean_mib\",\n",
    "            \"bw_mean_gib\",\n",
    "            \"bw_max_mib\",\n",
    "            \"bw_min_mib\",\n",
    "            \"mean_time\",\n",
    "            \"xsize_mib\",\n",
    "            \"num_tasks\",\n",
    "            \"tasks_per_node\",\n",
    "        )\n",
    "        .sort([\"backend\", \"experiment\", \"run\", \"run_index\", \"operation\"])\n",
    "    )\n",
    "    display(overview.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4df6a2",
   "metadata": {},
   "source": [
    "## Bandwidth Per Run\n",
    "\n",
    "実験・ジョブごとにブロック/転送サイズ別の平均帯域を可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1eb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ior_summary_df.is_empty():\n",
    "    print(\"No data to plot.\")\n",
    "else:\n",
    "    for experiment_df in ior_summary_df.partition_by(\"experiment\", maintain_order=True):\n",
    "        experiment = experiment_df[0, \"experiment\"] or \"unknown\"\n",
    "        for run_df in experiment_df.partition_by(\"run\", maintain_order=True):\n",
    "            run = run_df[0, \"run\"] or \"unknown\"\n",
    "            tidy = (\n",
    "                run_df\n",
    "                .select(\"config\", \"operation\", \"bw_mean_mib\")\n",
    "                .group_by([\"config\", \"operation\"], maintain_order=True)\n",
    "                .agg(pl.col(\"bw_mean_mib\").mean())\n",
    "                .pivot(values=\"bw_mean_mib\", index=\"config\", columns=\"operation\")\n",
    "                .sort(\"config\")\n",
    "            )\n",
    "            if tidy.is_empty():\n",
    "                continue\n",
    "            pdf = tidy.to_pandas().set_index(\"config\")\n",
    "            display(pdf)\n",
    "            fig, ax = plt.subplots(figsize=(9, 5), dpi=120)\n",
    "            pdf.plot(kind=\"bar\", ax=ax, width=0.7)\n",
    "            ax.set_xlabel(\"block / transfer size\")\n",
    "            ax.set_ylabel(\"Bandwidth (MiB/s)\")\n",
    "            ax.set_title(f\"{experiment} / {run} bandwidth\")\n",
    "            ax.grid(axis=\"y\", alpha=0.7, linestyle=\"--\", linewidth=1)\n",
    "            ax.yaxis.set_major_formatter(FuncFormatter(comma_formatter))\n",
    "            ax.legend(title=\"operation\", fontsize=10)\n",
    "            plt.xticks(rotation=45, ha=\"right\")\n",
    "            plt.tight_layout()\n",
    "            save(fig, f\"bandwidth_{slugify(experiment)}_{slugify(run)}\")\n",
    "            plt.show()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216e0cc",
   "metadata": {},
   "source": [
    "## Latency vs Bandwidth\n",
    "\n",
    "各操作の平均レイテンシと帯域の関係を散布図で確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44284e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ior_summary_df.is_empty():\n",
    "    print(\"No data to plot.\")\n",
    "else:\n",
    "    pdf = (\n",
    "        ior_summary_df\n",
    "        .select(\n",
    "            \"experiment\",\n",
    "            \"run\",\n",
    "            \"operation\",\n",
    "            \"config\",\n",
    "            \"bw_mean_mib\",\n",
    "            \"mean_time\",\n",
    "            \"xsize_mib\",\n",
    "        )\n",
    "        .to_pandas()\n",
    "    )\n",
    "    if pdf.empty:\n",
    "        print(\"No summary rows available for plotting.\")\n",
    "    else:\n",
    "        pdf[\"point_size\"] = 40 + 5 * pdf[\"xsize_mib\"].fillna(0)\n",
    "        fig, ax = plt.subplots(figsize=(8, 6), dpi=120)\n",
    "        for operation, group in pdf.groupby(\"operation\"):\n",
    "            ax.scatter(\n",
    "                group[\"bw_mean_mib\"],\n",
    "                group[\"mean_time\"],\n",
    "                s=group[\"point_size\"],\n",
    "                alpha=0.75,\n",
    "                edgecolors=\"black\",\n",
    "                linewidths=0.6,\n",
    "                label=operation,\n",
    "            )\n",
    "        for _, row in pdf.iterrows():\n",
    "            ax.annotate(\n",
    "                f\"{row['experiment']}\\n{row['config']}\",\n",
    "                (row[\"bw_mean_mib\"], row[\"mean_time\"]),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(5, 5),\n",
    "                fontsize=8,\n",
    "                alpha=0.7,\n",
    "            )\n",
    "        ax.set_xlabel(\"Bandwidth (MiB/s)\")\n",
    "        ax.set_ylabel(\"Mean time (s)\")\n",
    "        ax.set_title(\"Mean time vs bandwidth\")\n",
    "        ax.grid(alpha=0.5, linestyle=\"--\", linewidth=0.8)\n",
    "        ax.xaxis.set_major_formatter(FuncFormatter(comma_formatter))\n",
    "        ax.legend(title=\"operation\", fontsize=9)\n",
    "        plt.tight_layout()\n",
    "        save(fig, \"latency_vs_bandwidth\")\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debc814",
   "metadata": {},
   "source": [
    "## Detailed Test Results\n",
    "\n",
    "テスト内の各アクセス結果（write/read）を抽出し、ブロック/転送サイズごとの統計を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed3813",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ior_detail_df.is_empty():\n",
    "    print(\"No detailed IOR test entries to summarize.\")\n",
    "else:\n",
    "    detail_summary = (\n",
    "        ior_detail_df\n",
    "        .with_columns(\n",
    "            pl.col(\"block_kib\").cast(pl.Int64, strict=False),\n",
    "            pl.col(\"xfer_kib\").cast(pl.Int64, strict=False),\n",
    "        )\n",
    "        .group_by([\"backend\", \"experiment\", \"run\", \"run_index\", \"operation\", \"block_kib\", \"xfer_kib\"], maintain_order=True)\n",
    "        .agg(\n",
    "            pl.len().alias(\"samples\"),\n",
    "            pl.col(\"bw_mib\").mean().alias(\"bw_mib_mean\"),\n",
    "            pl.col(\"bw_mib\").max().alias(\"bw_mib_max\"),\n",
    "            pl.col(\"bw_mib\").min().alias(\"bw_mib_min\"),\n",
    "            pl.col(\"latency\").mean().alias(\"latency_mean\"),\n",
    "            pl.col(\"total_time\").mean().alias(\"total_time_mean\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            (pl.col(\"bw_mib_mean\") / 1024.0).alias(\"bw_gib_mean\"),\n",
    "            pl.format(\"blk {0} KiB / xfer {1} KiB\", pl.col(\"block_kib\"), pl.col(\"xfer_kib\")).alias(\"config\"),\n",
    "        )\n",
    "        .sort([\"backend\", \"experiment\", \"run\", \"run_index\", \"operation\", \"block_kib\", \"xfer_kib\"])\n",
    ")\n",
    "    display(detail_summary.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc9e4a6",
   "metadata": {},
   "source": [
    "## Bandwidth by Run Index\n",
    "\n",
    "同一ジョブ内の run_index ごとの帯域推移を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fdf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ior_detail_df.is_empty():\n",
    "    print(\"No IOR data to plot.\")\n",
    "else:\n",
    "    for experiment_df in ior_detail_df.partition_by(\"experiment\", maintain_order=True):\n",
    "        experiment = experiment_df[0, \"experiment\"] or \"unknown\"\n",
    "        for run_df in experiment_df.partition_by(\"run\", maintain_order=True):\n",
    "            run = run_df[0, \"run\"] or \"unknown\"\n",
    "            tidy = (\n",
    "                run_df\n",
    "                .select(\"run_index\", \"operation\", \"bw_mib\")\n",
    "                .drop_nulls(\"bw_mib\")\n",
    "                .group_by([\"run_index\", \"operation\"], maintain_order=True)\n",
    "                .agg(pl.col(\"bw_mib\").mean())\n",
    "                .sort([\"operation\", \"run_index\"])\n",
    "            )\n",
    "            if tidy.is_empty():\n",
    "                continue\n",
    "            pdf = tidy.to_pandas()\n",
    "            fig, ax = plt.subplots(figsize=(9, 5), dpi=120)\n",
    "            for operation, subset in pdf.groupby(\"operation\"):\n",
    "                ax.plot(\n",
    "                    subset[\"run_index\"],\n",
    "                    subset[\"bw_mib\"],\n",
    "                    marker=\"o\",\n",
    "                    linewidth=2,\n",
    "                    label=operation,\n",
    "                )\n",
    "            ax.set_xlabel(\"run index\")\n",
    "            ax.set_ylabel(\"Bandwidth (MiB/s)\")\n",
    "            ax.set_title(f\"{experiment} / {run} run index sweep\")\n",
    "            ax.grid(alpha=0.6, linestyle=\"--\", linewidth=0.9)\n",
    "            ax.yaxis.set_major_formatter(FuncFormatter(comma_formatter))\n",
    "            ax.legend(title=\"operation\", fontsize=10)\n",
    "            plt.tight_layout()\n",
    "            save(fig, f\"bandwidth_run_index_{slugify(experiment)}_{slugify(run)}\")\n",
    "            plt.show()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505a1a5",
   "metadata": {},
   "source": [
    "## Export Processed JSON\n",
    "\n",
    "整形済みのサマリと詳細データをJSONとして保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8eb1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ior_summary_df.is_empty() and ior_detail_df.is_empty():\n",
    "    print(\"No IOR results to export.\")\n",
    "else:\n",
    "    if not ior_summary_df.is_empty():\n",
    "        summary_out = DATA_DIR / \"ior_summary.json\"\n",
    "        summary_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "        summary_out.write_text(\n",
    "            json.dumps(ior_summary_df.to_pandas().to_dict(orient=\"records\"), ensure_ascii=False, indent=2)\n",
    "        )\n",
    "        print(f\"Wrote {summary_out}\")\n",
    "    else:\n",
    "        print(\"No summary records to export.\")\n",
    "    if not ior_detail_df.is_empty():\n",
    "        detail_out = DATA_DIR / \"ior_detail.json\"\n",
    "        detail_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "        detail_out.write_text(\n",
    "            json.dumps(ior_detail_df.to_pandas().to_dict(orient=\"records\"), ensure_ascii=False, indent=2)\n",
    "        )\n",
    "        print(f\"Wrote {detail_out}\")\n",
    "    else:\n",
    "        print(\"No detailed records to export.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchfs-plot",
   "language": "python",
   "name": "benchfs-plot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
